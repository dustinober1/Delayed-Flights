{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flight Delay Prediction - Feature Engineering\n",
    "\n",
    "This notebook focuses on creating advanced features for flight delay prediction, including weather integration, aircraft lag effects, and airport congestion metrics.\n",
    "\n",
    "## Objectives\n",
    "1. Create time-based cyclical features\n",
    "2. Engineer airport congestion metrics\n",
    "3. Build aircraft lag features (cascading delays)\n",
    "4. Integrate weather data\n",
    "5. Create airline and route-specific features\n",
    "6. Prepare final dataset for modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Add src to path\n",
    "sys.path.append('../src')\n",
    "\n",
    "from features.feature_engineering import FlightFeatureEngineer\n",
    "from data.weather_data import WeatherDataCollector\n",
    "from visualization.plots import FlightDelayVisualizer\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Processed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data from exploration notebook\n",
    "data_path = '../data/processed/airline_exploration.csv'\n",
    "\n",
    "if Path(data_path).exists():\n",
    "    df = pd.read_csv(data_path)\n",
    "    print(f\"Loaded {len(df):,} flights with {len(df.columns)} columns\")\n",
    "    print(f\"Date range: {df['FL_DATE'].min()} to {df['FL_DATE'].max()}\")\n",
    "else:\n",
    "    print(f\"Data file not found at {data_path}\")\n",
    "    print(\"Please run the 01_data_exploration.ipynb notebook first.\")\n",
    "    # Load sample data as fallback\n",
    "    from data.download_data import load_airline_data\n",
    "    df = load_airline_data(year=2023, sample_size=50000)\n",
    "    if df is not None:\n",
    "        df['delayed'] = (df['ARR_DELAY'] > 15).astype(int)\n",
    "        df = df[(df.get('CANCELLED', 0) != 1) & (df['ARR_DELAY'].notna())].copy()\n",
    "\n",
    "print(f\"\\nDataset shape: {df.shape}\")\n",
    "print(f\"Delay rate: {df['delayed'].mean()*100:.1f}%\")\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Initialize Feature Engineer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize feature engineer\n",
    "engineer = FlightFeatureEngineer()\n",
    "viz = FlightDelayVisualizer()\n",
    "\n",
    "print(\"Feature engineering pipeline initialized\")\n",
    "print(f\"Starting with {len(df.columns)} columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Time-Based Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create time-based features\n",
    "print(\"Creating time-based features...\")\n",
    "df_time = engineer.create_time_features(df)\n",
    "\n",
    "print(f\"Added {len(df_time.columns) - len(df.columns)} time-based features\")\n",
    "\n",
    "# Display new time features\n",
    "new_time_cols = [col for col in df_time.columns if col not in df.columns]\n",
    "print(f\"New time features: {new_time_cols}\")\n",
    "\n",
    "# Visualize cyclical features\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Month cyclical features\n",
    "axes[0, 0].scatter(df_time['month_sin'], df_time['month_cos'], c=df_time['month'], cmap='tab12')\n",
    "axes[0, 0].set_xlabel('Month Sin')\n",
    "axes[0, 0].set_ylabel('Month Cos')\n",
    "axes[0, 0].set_title('Month Cyclical Encoding')\n",
    "\n",
    "# Day of week cyclical features\n",
    "axes[0, 1].scatter(df_time['day_of_week_sin'], df_time['day_of_week_cos'], c=df_time['day_of_week'], cmap='tab7')\n",
    "axes[0, 1].set_xlabel('Day of Week Sin')\n",
    "axes[0, 1].set_ylabel('Day of Week Cos')\n",
    "axes[0, 1].set_title('Day of Week Cyclical Encoding')\n",
    "\n",
    "# Hour cyclical features (if available)\n",
    "if 'dep_hour_sin' in df_time.columns:\n",
    "    axes[1, 0].scatter(df_time['dep_hour_sin'], df_time['dep_hour_cos'], c=df_time['dep_hour'], cmap='tab24')\n",
    "    axes[1, 0].set_xlabel('Departure Hour Sin')\n",
    "    axes[1, 0].set_ylabel('Departure Hour Cos')\n",
    "    axes[1, 0].set_title('Departure Hour Cyclical Encoding')\n",
    "\n",
    "# Delay rate by time features\n",
    "if 'is_weekend' in df_time.columns:\n",
    "    weekend_delays = df_time.groupby('is_weekend')['delayed'].mean()\n",
    "    axes[1, 1].bar(['Weekday', 'Weekend'], weekend_delays.values, color=['skyblue', 'orange'])\n",
    "    axes[1, 1].set_ylabel('Delay Rate')\n",
    "    axes[1, 1].set_title('Delay Rate: Weekday vs Weekend')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "df = df_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Airport and Route Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create airport and route features\n",
    "print(\"Creating airport and route features...\")\n",
    "df_airport = engineer.create_airport_features(df)\n",
    "\n",
    "print(f\"Added {len(df_airport.columns) - len(df.columns)} airport/route features\")\n",
    "\n",
    "# Analyze major route impact\n",
    "if 'is_major_route' in df_airport.columns:\n",
    "    major_route_analysis = df_airport.groupby('is_major_route')['delayed'].agg(['count', 'mean'])\n",
    "    major_route_analysis.columns = ['flight_count', 'delay_rate']\n",
    "    major_route_analysis.index = ['Non-Major Route', 'Major Route']\n",
    "    \n",
    "    print(\"\\nMajor Route Analysis:\")\n",
    "    display(major_route_analysis)\n",
    "    \n",
    "    # Visualize\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "    \n",
    "    major_route_analysis['flight_count'].plot(kind='bar', ax=ax1, color='lightblue')\n",
    "    ax1.set_title('Flight Volume by Route Type')\n",
    "    ax1.set_ylabel('Number of Flights')\n",
    "    ax1.tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    major_route_analysis['delay_rate'].plot(kind='bar', ax=ax2, color='coral')\n",
    "    ax2.set_title('Delay Rate by Route Type')\n",
    "    ax2.set_ylabel('Delay Rate')\n",
    "    ax2.tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "df = df_airport"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Aircraft Lag Features (Cascading Delays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create aircraft lag features\n",
    "print(\"Creating aircraft lag features...\")\n",
    "print(\"This may take a few minutes for large datasets...\")\n",
    "\n",
    "df_lag = engineer.create_aircraft_lag_features(df)\n",
    "\n",
    "print(f\"Added {len(df_lag.columns) - len(df.columns)} aircraft lag features\")\n",
    "\n",
    "# Analyze aircraft lag impact\n",
    "if 'prev_flight_delayed' in df_lag.columns:\n",
    "    lag_analysis = df_lag.groupby('prev_flight_delayed')['delayed'].agg(['count', 'mean'])\n",
    "    lag_analysis.columns = ['flight_count', 'delay_rate']\n",
    "    lag_analysis.index = ['Previous Flight On-Time', 'Previous Flight Delayed']\n",
    "    \n",
    "    print(\"\\nAircraft Lag Effect Analysis:\")\n",
    "    display(lag_analysis)\n",
    "    \n",
    "    # Calculate correlation between previous and current delay\n",
    "    if 'prev_flight_arr_delay' in df_lag.columns:\n",
    "        valid_prev_delays = df_lag[df_lag['prev_flight_arr_delay'].notna()]\n",
    "        correlation = valid_prev_delays['prev_flight_arr_delay'].corr(valid_prev_delays['ARR_DELAY'])\n",
    "        print(f\"\\nCorrelation between previous and current flight delay: {correlation:.3f}\")\n",
    "        \n",
    "        # Visualize lag effect\n",
    "        fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "        \n",
    "        # Previous delay impact\n",
    "        lag_analysis['delay_rate'].plot(kind='bar', ax=axes[0], color='orange')\n",
    "        axes[0].set_title('Current Delay Rate by Previous Flight Status')\n",
    "        axes[0].set_ylabel('Current Flight Delay Rate')\n",
    "        axes[0].tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        # Scatter plot of previous vs current delay\n",
    "        sample_size = min(5000, len(valid_prev_delays))\n",
    "        sample_data = valid_prev_delays.sample(sample_size)\n",
    "        \n",
    "        axes[1].scatter(sample_data['prev_flight_arr_delay'], sample_data['ARR_DELAY'], \n",
    "                       alpha=0.3, s=10, color='red')\n",
    "        axes[1].set_xlabel('Previous Flight Delay (minutes)')\n",
    "        axes[1].set_ylabel('Current Flight Delay (minutes)')\n",
    "        axes[1].set_title('Previous vs Current Flight Delay')\n",
    "        axes[1].set_xlim(-50, 100)\n",
    "        axes[1].set_ylim(-50, 100)\n",
    "        \n",
    "        # Time since last flight distribution\n",
    "        if 'hours_since_last_flight' in df_lag.columns:\n",
    "            valid_hours = df_lag[df_lag['hours_since_last_flight'].notna() & \n",
    "                                (df_lag['hours_since_last_flight'] < 24)]\n",
    "            \n",
    "            axes[2].hist(valid_hours['hours_since_last_flight'], bins=30, alpha=0.7, color='green')\n",
    "            axes[2].set_xlabel('Hours Since Last Flight')\n",
    "            axes[2].set_ylabel('Frequency')\n",
    "            axes[2].set_title('Distribution of Time Between Flights')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "df = df_lag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Airport Congestion Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create congestion features\n",
    "print(\"Creating airport congestion features...\")\n",
    "df_congestion = engineer.create_congestion_features(df)\n",
    "\n",
    "print(f\"Added {len(df_congestion.columns) - len(df.columns)} congestion features\")\n",
    "\n",
    "# Analyze congestion impact\n",
    "congestion_cols = ['origin_departures_per_hour', 'dest_arrivals_per_hour']\n",
    "available_congestion = [col for col in congestion_cols if col in df_congestion.columns]\n",
    "\n",
    "if available_congestion:\n",
    "    # Create congestion level categories\n",
    "    for col in available_congestion:\n",
    "        if col in df_congestion.columns:\n",
    "            df_congestion[f'{col}_category'] = pd.cut(df_congestion[col],\n",
    "                                                    bins=[0, 10, 20, 30, float('inf')],\n",
    "                                                    labels=['Low', 'Medium', 'High', 'Very High'])\n",
    "    \n",
    "    # Analyze congestion vs delays\n",
    "    if 'origin_departures_per_hour_category' in df_congestion.columns:\n",
    "        congestion_analysis = df_congestion.groupby('origin_departures_per_hour_category')['delayed'].agg(['count', 'mean'])\n",
    "        congestion_analysis.columns = ['flight_count', 'delay_rate']\n",
    "        \n",
    "        print(\"\\nOrigin Airport Congestion Analysis:\")\n",
    "        display(congestion_analysis)\n",
    "        \n",
    "        # Visualize congestion impact\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "        \n",
    "        congestion_analysis['delay_rate'].plot(kind='bar', ax=axes[0], color='purple')\n",
    "        axes[0].set_title('Delay Rate by Origin Airport Congestion')\n",
    "        axes[0].set_ylabel('Delay Rate')\n",
    "        axes[0].tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        # Scatter plot of congestion vs delay\n",
    "        sample_data = df_congestion.sample(min(5000, len(df_congestion)))\n",
    "        axes[1].scatter(sample_data['origin_departures_per_hour'], sample_data['delayed'], \n",
    "                       alpha=0.3, s=10, color='purple')\n",
    "        axes[1].set_xlabel('Departures per Hour')\n",
    "        axes[1].set_ylabel('Delayed (0/1)')\n",
    "        axes[1].set_title('Airport Congestion vs Delay Probability')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "df = df_congestion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Airline Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create airline features\n",
    "print(\"Creating airline-specific features...\")\n",
    "df_airline = engineer.create_airline_features(df)\n",
    "\n",
    "print(f\"Added {len(df_airline.columns) - len(df.columns)} airline features\")\n",
    "\n",
    "# Analyze airline features\n",
    "airline_feature_cols = ['airline_avg_delay', 'airline_delay_std', 'route_airline_avg_delay']\n",
    "available_airline_features = [col for col in airline_feature_cols if col in df_airline.columns]\n",
    "\n",
    "if available_airline_features:\n",
    "    print(\"\\nAirline Feature Statistics:\")\n",
    "    display(df_airline[available_airline_features].describe())\n",
    "    \n",
    "    # Visualize airline feature distributions\n",
    "    fig, axes = plt.subplots(1, len(available_airline_features), figsize=(5*len(available_airline_features), 5))\n",
    "    \n",
    "    if len(available_airline_features) == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    for i, col in enumerate(available_airline_features):\n",
    "        df_airline[col].hist(bins=30, ax=axes[i], alpha=0.7)\n",
    "        axes[i].set_title(f'Distribution of {col}')\n",
    "        axes[i].set_xlabel(col)\n",
    "        axes[i].set_ylabel('Frequency')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "df = df_airline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Weather Data Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weather data integration\n",
    "print(\"Integrating weather data...\")\n",
    "print(\"Note: This uses mock weather data for demonstration. Set WEATHER_API_KEY environment variable for real data.\")\n",
    "\n",
    "weather_collector = WeatherDataCollector()\n",
    "\n",
    "# For demo purposes, we'll add mock weather data to a sample\n",
    "sample_size = min(1000, len(df))  # Limit for demo\n",
    "df_sample = df.sample(sample_size, random_state=42)\n",
    "\n",
    "# Add mock weather features\n",
    "np.random.seed(42)\n",
    "weather_features = {\n",
    "    'origin_temperature': np.random.normal(60, 20, sample_size),\n",
    "    'origin_humidity': np.random.normal(50, 20, sample_size),\n",
    "    'origin_wind_speed': np.random.gamma(2, 5, sample_size),\n",
    "    'origin_visibility': np.random.gamma(5, 2, sample_size),\n",
    "    'origin_precipitation': np.random.exponential(0.1, sample_size),\n",
    "    'dest_temperature': np.random.normal(65, 18, sample_size),\n",
    "    'dest_humidity': np.random.normal(55, 18, sample_size),\n",
    "    'dest_wind_speed': np.random.gamma(2, 5, sample_size),\n",
    "    'dest_visibility': np.random.gamma(5, 2, sample_size),\n",
    "    'dest_precipitation': np.random.exponential(0.1, sample_size)\n",
    "}\n",
    "\n",
    "for feature, values in weather_features.items():\n",
    "    df_sample[feature] = values\n",
    "\n",
    "print(f\"Added weather features to {sample_size} flights\")\n",
    "print(f\"Weather features: {list(weather_features.keys())}\")\n",
    "\n",
    "# Create weather-derived features\n",
    "df_weather = engineer.create_weather_features(df_sample)\n",
    "\n",
    "weather_derived = [col for col in df_weather.columns if col not in df_sample.columns]\n",
    "print(f\"\\nDerived weather features: {weather_derived}\")\n",
    "\n",
    "# Analyze weather impact (using sample with weather data)\n",
    "if weather_derived:\n",
    "    print(\"\\nWeather Impact Analysis:\")\n",
    "    \n",
    "    # Analyze adverse weather impact\n",
    "    weather_impact_cols = [col for col in weather_derived if 'adverse_weather' in col]\n",
    "    \n",
    "    for col in weather_impact_cols:\n",
    "        if col in df_weather.columns:\n",
    "            impact = df_weather.groupby(col)['delayed'].agg(['count', 'mean'])\n",
    "            impact.columns = ['flight_count', 'delay_rate']\n",
    "            impact.index = ['Normal Weather', 'Adverse Weather']\n",
    "            print(f\"\\n{col}:\")\n",
    "            display(impact)\n",
    "    \n",
    "    # Visualize weather impact\n",
    "    viz.plot_weather_impact(df_weather)\n",
    "\n",
    "# For the main dataset, we'll continue without weather features\n",
    "# In a real scenario, you would integrate weather data for the full dataset\n",
    "print(\"\\nContinuing with main dataset (without weather features for this demo)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Categorical Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical features\n",
    "print(\"Encoding categorical features...\")\n",
    "df_encoded = engineer.encode_categorical_features(df)\n",
    "\n",
    "print(f\"Added {len(df_encoded.columns) - len(df.columns)} encoded features\")\n",
    "\n",
    "# Show encoding results\n",
    "encoded_cols = [col for col in df_encoded.columns if col.endswith('_encoded')]\n",
    "print(f\"Encoded features: {encoded_cols}\")\n",
    "\n",
    "if encoded_cols:\n",
    "    print(\"\\nSample of encoded values:\")\n",
    "    display(df_encoded[encoded_cols].head(10))\n",
    "\n",
    "df = df_encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Final Feature Selection and Dataset Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final feature summary\n",
    "print(\"=== FEATURE ENGINEERING SUMMARY ===\")\n",
    "print(f\"Original columns: {len(df.columns)}\")\n",
    "print(f\"Final dataset shape: {df.shape}\")\n",
    "\n",
    "# Categorize features\n",
    "feature_categories = {\n",
    "    'Time Features': [col for col in df.columns if any(x in col for x in ['hour', 'day', 'month', 'weekend', 'holiday', 'sin', 'cos'])],\n",
    "    'Airport Features': [col for col in df.columns if any(x in col for x in ['origin', 'dest', 'major', 'route', 'departures', 'arrivals'])],\n",
    "    'Aircraft Features': [col for col in df.columns if any(x in col for x in ['prev_flight', 'aircraft', 'hours_since', 'tail'])],\n",
    "    'Airline Features': [col for col in df.columns if any(x in col for x in ['airline', 'carrier'])],\n",
    "    'Weather Features': [col for col in df.columns if any(x in col for x in ['weather', 'temperature', 'wind', 'visibility', 'precipitation'])],\n",
    "    'Encoded Features': [col for col in df.columns if col.endswith('_encoded')],\n",
    "    'Target': ['delayed']\n",
    "}\n",
    "\n",
    "for category, features in feature_categories.items():\n",
    "    available_features = [f for f in features if f in df.columns]\n",
    "    print(f\"\\n{category} ({len(available_features)}): {available_features[:5]}{'...' if len(available_features) > 5 else ''}\")\n",
    "\n",
    "# Check for missing values in engineered features\n",
    "missing_summary = df.isnull().sum()\n",
    "missing_features = missing_summary[missing_summary > 0]\n",
    "\n",
    "if len(missing_features) > 0:\n",
    "    print(\"\\n=== MISSING VALUES IN ENGINEERED FEATURES ===\")\n",
    "    print(missing_features.head(10))\n",
    "else:\n",
    "    print(\"\\n✅ No missing values in engineered features\")\n",
    "\n",
    "# Feature correlation with target\n",
    "numerical_features = df.select_dtypes(include=[np.number]).columns\n",
    "target_correlations = df[numerical_features].corr()['delayed'].abs().sort_values(ascending=False)\n",
    "\n",
    "print(\"\\n=== TOP 15 FEATURES BY CORRELATION WITH TARGET ===\")\n",
    "display(target_correlations.head(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize feature importance through correlation\n",
    "top_features = target_correlations.head(20).index.tolist()\n",
    "\n",
    "if len(top_features) > 1:\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    # Create correlation heatmap for top features\n",
    "    correlation_matrix = df[top_features].corr()\n",
    "    \n",
    "    mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))\n",
    "    sns.heatmap(correlation_matrix, mask=mask, annot=True, cmap='coolwarm', center=0,\n",
    "               square=True, linewidths=0.5, cbar_kws={\"shrink\": .8})\n",
    "    plt.title('Correlation Matrix - Top 20 Features')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save engineered dataset\n",
    "output_path = '../data/processed/flight_features_engineered.csv'\n",
    "df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"\\n✅ Engineered dataset saved to {output_path}\")\n",
    "print(f\"Final shape: {df.shape}\")\n",
    "print(f\"Target distribution: {df['delayed'].mean()*100:.1f}% delayed\")\n",
    "\n",
    "# Save feature metadata\n",
    "feature_metadata = {\n",
    "    'total_features': len(df.columns),\n",
    "    'feature_categories': {k: len([f for f in v if f in df.columns]) for k, v in feature_categories.items()},\n",
    "    'top_features': target_correlations.head(15).to_dict(),\n",
    "    'dataset_shape': df.shape,\n",
    "    'delay_rate': df['delayed'].mean()\n",
    "}\n",
    "\n",
    "import json\n",
    "with open('../data/processed/feature_metadata.json', 'w') as f:\n",
    "    json.dump(feature_metadata, f, indent=2)\n",
    "\n",
    "print(\"\\n✅ Feature metadata saved\")\n",
    "print(\"\\n=== READY FOR MODELING ===\")\n",
    "print(\"Proceed to 03_model_training.ipynb for model development\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}